{
    "devDependencies": {
        "genaiscript": "^1.124.3",
        "prettier": "^3.5.3"
    },
    "scripts": {
        "postinstall": "genaiscript scripts fix",
        "postupdate": "genaiscript scripts fix",
        "upgrade": "npx --yes npm-check-updates -u && npm install",
        "genaiscript": "genaiscript",
        "az:login": "az login --scope api://trapi/.default --use-device-code",
        "genai": "genaiscript run",
        "gcm": "genaiscript run gcm -m github:gpt-4o",
        "gcm:ollama": "genaiscript run gcm -m ollama:gemma3:27b",
        "serve": "genaiscript serve",
        "build": "genaiscript scripts compile",
        "promptpex": "genaiscript run promptpex",
        "dev": "genaiscript run dev",
        "dev:fabric": "genaiscript run dev --vars \"fabric=v1.4.149\" --vars \"samplePrompts=1\"",
        "lint": "prettier --write src/**/*.mts",
        "test": "genaiscript run test --env .env.test",
        "promptpex:demo:ollama": "genaiscript run promptpex \"samples/demo/demo.prompty\" --vars \"compliance=true\" --vars \"models=ollama:llama3.2:1b;ollama:qwen2.5:3b\" --vars cache=true --vars evalCache=true",
        "promptpex:demo:github": "genaiscript run promptpex \"samples/demo/demo.prompty\" --vars \"compliance=true\" --model \"github:gpt-4o\" --vars \"models=github:gpt-4o-mini;github:Phi-4-mini-instruct\" --vars cache=true --vars evalCache=true",
        "promptpex:demo:azure": "genaiscript run promptpex \"samples/demo/demo.prompty\" --vars \"compliance=true\" --model \"azure:gpt-4o_2024-11-20\" --vars \"models=azure:gpt-4o-mini_2024-07-18;azure:gpt-35-turbo_1106\" --vars cache=true --vars evalCache=true",
        "promptpex:speech-tag:github": "genaiscript run paper \"samples/speech-tag/speech-tag.prompty\" --vars \"evals=true\" --vars \"models=github:gpt-4o-mini;github:Phi-4-mini-instruct\"",
        "promptpex:speech-tag:azure": "genaiscript run paper \"samples/speech-tag/speech-tag.prompty\" --vars \"evals=true\" --model \"azure:gpt-4o_2024-11-20\" --vars \"models=azure:gpt-4o-mini_2024-07-18;azure:gpt-35-turbo_1106\" --vars \"out=evals/paper\"",
        "promptpex:paper-newm-newp": "genaiscript run paper \"samples/speech-tag/speech-tag.prompty\" \"samples/text-to-p/text-to-p.prompty\" \"samples/openai-examples/elements.prompty\" \"samples/big-prompt-lib/art-prompt.prompty\" \"samples/prompt-guide/extract-names.prompty\" \"samples/text-classification/classify-input-text.prompty\" \"samples/big-prompt-lib/sentence-rewrite.prompty\" \"samples/azure-ai-studio/shakespearean-writing-assistant.prompty\" \"samples/big-prompt-lib/wine-expert.prompty\" \"samples/big-prompt-lib/text-to-emoji.prompty\" \"samples/big-prompt-lib/topic-breakdown.prompty\" \"samples/big-prompt-lib/shield-challenge.prompty\" \"samples/big-prompt-lib/survival.prompty\" \"samples/big-prompt-lib/email-responder.prompty\" \"samples/hugging-face/llm-as-judge.prompty\" --vars \"evals=true\" --vars \"models=ollama:deepseek-r1:32b;azure:gpt-4o-mini_2024-07-18;ollama:qwen2.5:3b\" --vars \"out=evals/p-newm-newp-02-14\"",
        "promptpex:paper-speech-tag": "genaiscript run paper \"samples/speech-tag/speech-tag.prompty\" --vars \"evals=true\" --vars \"models=azure:gpt-4o-mini_2024-07-18;ollama:gemma2:9b;ollama:qwen2.5:3b;ollama:llama3.2:1b\" --vars \"out=evals/paper-speech-tag\"",
        "promptpex:paper-speech-tag-tplus": "genaiscript run paper \"samples/speech-tag/speech-tag.prompty\"  --vars \"splitRules=true\" --vars \"maxRulesPerTestGeneration=5\" --vars \"testGenerations=1\" --vars \"evals=true\" --vars \"models=azure:gpt-4o-mini_2024-07-18;ollama:gemma2:9b;ollama:qwen2.5:3b;ollama:llama3.2:1b\" --vars \"out=evals/paper-speech-tag-tplus\"",
        "promptpex:paper-speech-tag-cache": "genaiscript run paper \"samples/speech-tag/speech-tag.prompty\" --vars \"evals=true\" --vars \"cache=true\" --vars \"models=azure:gpt-4o-mini_2024-07-18;ollama:gemma2:9b;ollama:qwen2.5:3b;ollama:llama3.2:1b\" --vars \"out=evals/paper-speech-tag-tplus\"",
        "promptpex:paper-speech-tag-1tpr-3rpt": "genaiscript run paper \"samples/speech-tag/speech-tag.prompty\" --vars \"evals=true\" --vars \"models=azure:gpt-4o-mini_2024-07-18;ollama:gemma2:9b;ollama:qwen2.5:3b;ollama:llama3.2:1b\" --vars \"out=evals/paper-speech-tag-1tpr-3rpt\" --vars \"testsPerRule=1\" --vars \"runsPerTest=5\" ",
        "promptpex:paper-speech-tag-4o": "genaiscript run paper \"samples/speech-tag/speech-tag.prompty\" --vars \"evals=true\" --vars \"models=ollama:phi4;ollama:qwen2.5:3b\" --vars \"out=evals/paper-speech-tag-4o\"",
        "promptpex:paper-classify-input-text": "genaiscript run paper \"samples/text-classification/classify-input-text.prompty\" --vars \"evals=true\" --vars \"models=azure:gpt-4o-mini_2024-07-18;ollama:gemma2:9b;ollama:qwen2.5:3b;ollama:llama3.2:1b\" --vars \"out=evals/paper-classify-input-text\"",
        "promptpex:paper-art-prompt": "genaiscript run paper \"samples/big-prompt-lib/art-prompt.prompty\" --vars \"evals=true\" --vars \"models=azure:gpt-4o-mini_2024-07-18;ollama:gemma2:9b;ollama:qwen2.5:3b;ollama:llama3.2:1b\" --vars \"out=evals/paper-art-prompt\"",
        "promptpex:paper": "genaiscript run paper \"samples/speech-tag/speech-tag.prompty\" \"samples/text-to-p/text-to-p.prompty\" \"samples/openai-examples/elements.prompty\" \"samples/big-prompt-lib/art-prompt.prompty\" \"samples/prompt-guide/extract-names.prompty\" \"samples/text-classification/classify-input-text.prompty\" \"samples/big-prompt-lib/sentence-rewrite.prompty\" \"samples/azure-ai-studio/shakespearean-writing-assistant.prompty\" --vars \"evals=true\" --vars \"models=azure:gpt-4o-mini_2024-07-18;ollama:gemma2:9b;ollama:qwen2.5:3b;ollama:llama3.2:1b\" --vars \"out=evals/paper\"",
        "promptpex:paper-tplus": "genaiscript run paper \"samples/speech-tag/speech-tag.prompty\" \"samples/text-to-p/text-to-p.prompty\" \"samples/openai-examples/elements.prompty\" \"samples/big-prompt-lib/art-prompt.prompty\" \"samples/prompt-guide/extract-names.prompty\" \"samples/text-classification/classify-input-text.prompty\" \"samples/big-prompt-lib/sentence-rewrite.prompty\" \"samples/azure-ai-studio/shakespearean-writing-assistant.prompty\"  --vars \"splitRules=true\" --vars \"maxRulesPerTestGeneration=5\" --vars \"testGenerations=1\" --vars \"evals=true\" --vars \"models=azure:gpt-4o-mini_2024-07-18;ollama:gemma2:9b;ollama:qwen2.5:3b;ollama:llama3.2:1b\" --vars \"out=evals/paper-tplus\"",
        "ollama": "npm run ollama:stop && npm run ollama:start",
        "ollama:start": "docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama -e OLLAMA_FLASH_ATTENTION=1 -e OLLAMA_KV_CACHE_TYPE=q8_0 ollama/ollama",
        "ollama:stop": "docker stop ollama && docker rm ollama"
    }
}
